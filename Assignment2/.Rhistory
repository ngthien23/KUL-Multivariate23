install.packages("languageserver")
install.packages(c("vroom", "xml2"))
library(languageserver)
remove.packages("languageserver")
install.packages("languageserver")
install.packages("languageserver")
install.packages("languageserver")
install.packages("tidyverse", "survival", "KMsurv", "survminer")
install.packages("tidyverse", "survival", "KMsurv", "survminer")
install.packages("tidyverse", "KMsurv", "survminer")
install.packages("tidyverse", "KMsurv", "survminer", dependencies=TRUE, repos='http://cran.rstudio.com/')
install.packages("tidyverse")
install.packages("KMsurv")
install.packages("survminer")
install.packages("languageserver")
install.packages("lazyeval")
install.packages(c("askpass", "broom", "bslib", "cachem", "cpp11", "curl", "cyclocomp", "dbplyr", "digest", "dplyr", "evaluate", "fontawesome", "fs", "gargle", "ggplot2", "googledrive", "googlesheets4", "gtable", "haven", "htmltools", "httr", "jsonlite", "knitr", "labeling", "languageserver", "lintr", "lme4", "markdown", "MatrixModels", "minqa", "mvtnorm", "openssl", "pkgload", "prettyunits", "processx", "purrr", "quantreg", "Rcpp", "readxl", "rematch", "remotes", "rmarkdown", "rstudioapi", "sass", "styler", "sys", "testthat", "tinytex", "tzdb", "uuid", "vctrs", "viridisLite", "waldo", "xfun", "xml2"))
install.packages("mnormt")
install.packages("copula")
install.packages("candisc")
install.packages("marima")
install.packages("forecast")
install.packages("timeSeries")
install.packages("quantmod")
install.packages("randomForestExplainer")
install.packages("class")
install.packages("e1071")
install.packages("HDclassif")
library(stats)
library(MASS)
library(mclust)
library(HDclassif)
# loading the data and getting the true values
load('mnist_task2.Rdata')
setwd("C:/Users/camd1/OneDrive - KU Leuven/2. Master of Statistics and Data Science 22-24/Year 1/Semester 1/Multivariate Statistics/Assignments/Assignment2")
library(stats)
library(MASS)
library(mclust)
library(HDclassif)
# loading the data and getting the true values
load('mnist_task2.Rdata')
true_labels <- as.numeric(as.factor(target))
#Hierarchical clustering on squared Euclidean distances using the method of Ward
dist_data <- dist(data, method = "euclidean",diag = TRUE, upper = TRUE)
hier_clust <- hclust(dist_data,"ward.D2")
#Cutting the tree to 4 clusters
clust_hier_4 <- cutree(hier_clust, k = 4)
table(clust_hier_4)
#K-means clustering
kmeans_result <-kmeans(data,4,nstart=50,iter.max=200)
varciance_k<-k4_data$betweenss/k4_data$totss
#K-means clustering
kmeans_result <-kmeans(data,4,nstart=50,iter.max=200)
varciance_k<-k4_data$betweenss/k4_data$totss
#install.packages("plfm")
#help(anger)
#head(anger)
library(plfm)
#a.
# anger data is a 3D array
# Aggregate across situations (the second dimension is for situations)
person_behavior_aggregated <- apply(anger$data, MARGIN =3, FUN = rowSums)
dim(person_behavior_aggregated)
# We have 101 persons and 8 behaviors, the result is a 101 x 8 matrix
EuclideanDistance <- dist(person_behavior_aggregated, method = "euclidean",
diag = TRUE, upper = TRUE)
# hierarchical clustering Ward bimodal data on squared Euclidean distance
hiclust_ward<- hclust(EuclideanDistance, "ward.D2")
par(pty="s")
plot(hiclust_ward,hang=-1)
#Save the cluster membership variable of the 2-cluster solution
clusters <- cutree(hiclust_ward, k = 1:5)
nclust <- 2
#centroid
stat<-describeBy(person_behavior_aggregated, clusters, mat=TRUE)
library(stats)
library(MASS)
library(mclust)
library(HDclassif)
# loading the data and getting the true values
load('mnist_task2.Rdata')
true_labels <- as.numeric(as.factor(target))
data= scale(data,center=TRUE, scale=FALSE)
#Hierarchical clustering on squared Euclidean distances using the method of Ward
dist_data <- dist(data, method = "euclidean",diag = TRUE, upper = TRUE)
hier_clust <- hclust(dist_data,"ward.D2")
#Cutting the tree to 4 clusters
clust_hier_4 <- cutree(hier_clust, k = 4)
table(clust_hier_4)
#K-means clustering
kmeans_result <-kmeans(data,4,nstart=500,iter.max=2000)
varciance_k<-kmeans_result$betweenss/kmeans_result$totss
varciance_k
#HDDC clustering AkjBkQkD with hierarchical clustering
hddc_AkjBkQkD_hier <- hddc(data, K = 4, model = "AkjBkQkD",d_select = "Cattell" ,init.vector = clust_hier_4,
threshold = 0.05)
#HDDC clustering AkjBkQkD with kmeans
hddc_AkjBkQkD_means <- hddc(data, K = 4, model = "AkjBkQkD",d_select = "Cattell" ,init.vector = kmeans_result,
threshold = 0.05)
#HDDC clustering AkjBQkD with hierarchical clustering
hddc_AkjBQkD_hier<-hddc(data, K = 4, model = "AkjBQkD",d_select = "Cattell" ,init.vector = clust_hier_4,
threshold = 0.05)
#HDDC clustering AkjBkQkD with kmeans
hddc_AkjBQkD_means<-hddc(data, K = 4, model = "AkjBQkD",d_select = "Cattell" ,init.vector = kmeans_result,
threshold = 0.05)
#Calculating the ARI for each method
ari_hier <- adjustedRandIndex(true_labels, clust_hier_4)
ari_kmeans <- adjustedRandIndex(true_labels, kmeans_result$cluster)
ari_hddc_AkjBkQkD_hier <- adjustedRandIndex(true_labels, hddc_AkjBkQkD_hier$class)
ari_hddc_AkjBQkD_hier<- adjustedRandIndex(true_labels, hddc_AkjBQkD_hier$class)
ari_hddc_AkjBkQkD_k<- adjustedRandIndex(true_labels, hddc_AkjBkQkD_means$class)
ari_hddc_AkjBQkD_k<- adjustedRandIndex(true_labels, hddc_AkjBQkD_means$class)
#Creating a dataframe with the ARI values
ari_values <- c(ari_hier, ari_kmeans, ari_hddc_AkjBkQkD_hier, ari_hddc_AkjBQkD_hier, ari_hddc_AkjBkQkD_k, ari_hddc_AkjBQkD_k)
method_names <- c('Hierarchical', 'K-means', 'HDDC AkjBkQkD Hierarchical', 'HDDC AkjBQkD Hierarchical', 'HDDC AkjBkQkD K-means', 'HDDC AkjBQkD K-means')
ari_df <- data.frame(Method = method_names, ARI = ari_values)
print(ari_df)
# Visualizing the higest ARI with 2 PCA on centerd data
prcomp<- prcomp(data, center = TRUE, scale. = FALSE)
pc2_data <- prcomp$x[, 1:2]
plot(pc2_data, col = clust_hier_4, main = "Hierarchical clustering", xlab = "PC1", ylab = "PC2")
library(plfm)
library(psych)
# Aggregate across situations (the second dimension is for situations)
person_behavior_aggregated <- apply(anger$data, MARGIN =3, FUN = rowSums)
# Check the dimensions of the aggregated matrix
dim(person_behavior_aggregated)
# We have 101 persons and 8 behaviors, the result is a 101 x 8 matrix
# compute squared Euclidean distances
help(dist)
EuclideanDistance <- dist(person_behavior_aggregated, method = "euclidean",
diag = TRUE, upper = TRUE)
EuclideanDistance
#SquaredEuclideanDistance <- EuclideanDistance^2
#SquaredEuclideanDistance
# hierarchical clustering Ward bimodal data
# cluster on squared Euclidean distance
hiclust_ward<- hclust(EuclideanDistance, "ward.D2")
par(pty="s")
plot(hiclust_ward,hang=-1)
#Ward’s method fails to capture the difference in the true modality of the two samples.
#Save the cluster membership variable of the 2-cluster solution
clusters <- cutree(hiclust_ward, k = 2)
clusters
nclust <- 2
#centroid
stat<-describeBy(person_behavior_aggregated, clusters, mat=TRUE)
stat
hcenter <- matrix(stat[,5],nrow=nclust)
hcenter
rownames(hcenter) <- paste("c_",rep(1:nclust),sep="")
colnames(hcenter) <- c(colnames(anger$freq2))
round(hcenter,2)
plot(hiclust_ward,hang=-1)
library(plfm)
library(psych)
help(anger)
head(anger)
#a)
# anger data is a 3D array
# Aggregate across situations (the second dimension is for situations)
person_behavior_aggregated <- apply(anger$data, MARGIN =3, FUN = rowSums)
# Check the dimensions of the aggregated matrix
dim(person_behavior_aggregated)
# We have 101 persons and 8 behaviors, the result is a 101 x 8 matrix
# compute squared Euclidean distances
help(dist)
EuclideanDistance <- dist(person_behavior_aggregated, method = "euclidean",
diag = TRUE, upper = TRUE)
EuclideanDistance
#SquaredEuclideanDistance <- EuclideanDistance^2
#SquaredEuclideanDistance
# hierarchical clustering Ward bimodal data
# cluster on squared Euclidean distance
hiclust_ward<- hclust(EuclideanDistance, "ward.D2")
par(pty="s")
plot(hiclust_ward,hang=-1)
#Ward’s method fails to capture the difference in the true modality of the two samples.
#Save the cluster membership variable of the 2-cluster solution
clusters <- cutree(hiclust_ward, k = 2)
clusters
nclust <- 2
#centroid
stat<-describeBy(person_behavior_aggregated, clusters, mat=TRUE)
stat
hcenter <- matrix(stat[,5],nrow=nclust)
hcenter
rownames(hcenter) <- paste("c_",rep(1:nclust),sep="")
colnames(hcenter) <- c(colnames(anger$freq2))
round(hcenter,2)
# Combine the aggregated matrix and cluster assignments
data_with_clusters <- data.frame(person_behavior_aggregated, cluster = clusters)
profile_vectors <- aggregate(. ~ cluster, data = data_with_clusters, sum)
profile_vectors <- profile_vectors[, -1]
# Define the new column names
new_column_names <- c(
"fly off the handle",
"quarrel",
"leave",
"avoid",
"pour out one's hart",
"tell one's story",
"make up",
"clear up the matter"
)
# Assign the new column names to 'profile_vectors'
colnames(profile_vectors) <- new_column_names
final_freq1 <- rbind(anger$freq1, profile_vectors)
final_freq1
library(ca)
#H0: bahabior and situations are statistically independent
#if the Pearson-Chi square test indicates that Xand Y are statistically
#dependent, it is meaningful to use CA to further study the nature of the
#relation between Xand Y.
chisq.test(final_freq1)
#p-value is small enough to reject null
ca.out <- ca(final_freq1)
#slide 19 of ch10
summary(ca.out)
#slide 20
par(pty="s", cex=0.9)
plot(ca.out, mass = TRUE,arrows = c(TRUE, FALSE),)
